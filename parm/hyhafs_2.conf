## This is a UNIX conf file that contains all information relating to
# the HWRF configuration.  UNIX conf is used because of how easy it is
# to parse (even GrADS can do it).  The syntax:
#
#      [section]
#      var = value
#
# For generation of namelists for WRF, WPS and other Fortran programs,
# we use this syntax:
#
#     [section]
#     namelist.nlvar = value
#
# to set the value of namelist &namelist's nlvar variable.  Also, the
# special variable "namelist" lists additional conf sections to
# recurse into to get more namelist variables after the current conf
# section is parsed.  Any variable will only be set once: the first
# time it is seen.

## Sets basic configuration options used by all components.
#
# This section sets basic configuration options used by all components.  
# Several special variables in this section are set by the HWRFConfig 
# object itself, which will overwrite them if they're set in this
# file:
# * YMDHM = analysis time (201304261830 = April 26, 2013, 18:30 UTC)
# * YMDH = analysis time excluding minute (2013042618)
# * YMD = analysis time, excluding hour and minute
# * year, YYYY = analysis time's year (ie.: 2013)
# * YY = last two digits of year
# * century, CC = first two digits of year
# * month, MM = analysis time's month (ie.: 04)
# * day, DD = analysis time's day (ie.: 26)
# * hour, cyc, HH = analysis time's hour (ie.: 18)
# * minute, min = analysis time's minute (ie.: 30)
#
# There may be additional variables depending on what subclass (if
# any) of the HWRFConfig is used.  You must specify the mandatory EXPT
# value, which is the name of the experiment to run.
[config]
#EXPT=HWRF ;; Experiment name, used for finding installation locations
EXPT=HMON ;;

## Section that specifies the configuration for the forecast job.
forecast_section=runwrf

## The storm label: storm1, storm2, etc.
#
# This string is always "storm" followed by a single-digit number.  It
# is used by NCO to decide where certain files and directories are
# located.  It also gives automation systems a way of determining
# storm filenames without having to know the storm name or ID.
stormlabel=storm{storm_num}

## Where to put the HWRF database file
#
# Location for the HWRF database file.  Note that there must be only
# one of these per workflow (storm, cycle).  The HWRFConfig class will
# also set the dsetfile variable if it is not already set:
datastore={WORKhwrf}/hwrf_state.sqlite3

## The main configuration file.
CONFhwrf={com}/{stormlabel}.conf

ENS=99   ;; The ensemble number; do not change.  The laucher sets it.
ensize=0 ;; Ensemble size; do not change.  The parm/hwrf_ensemble_2014.conf overrides it.

GFSVER=PROD2016 ;; GFS version: PROD2012 or PROD2014

## Configure file and directory paths
[dir]
intercom={WORKhwrf}/intercom  ;; dir for communicating data files between jobs
lockdir={WORKhwrf}/lock       ;; lock files for post-processing

PARMhycom={PARMhwrf}/hycom/  ;; hycom parameter files

## Domain center location file in COM.
#
# This is the full path to the domain center location file, which MUST
# be in com.  It is used to determine whether a cycle has a com
# directory:
domlocfile={com}/{vit[stnum]:02d}{vit[basin1lc]}.{vit[YMDH]}.domain.center

## File to check in a prior cycle's com, to see if the cycle exists.
#
# File to use to check if a prior cycle exists for a given storm.
# This only applies to the single storm HWRF.  It should not use the
# vit[] variable; instead, use oldvit[].
HISTCHECK={oldcom}/{oldvit[stnum]:02d}{oldvit[basin1lc]}.{oldvit[YMDH]}.domain.center

## Executable program locations
[exe]
# from moduleis set

wgrib2={ENV[WGRIB2]}
cnvgrib={ENV[CNVGRIB]}

wgrib={ENV[WGRIB]}
grbindex={ENV[GRIBINDEX]}
mpiserial={EXEChwrf}/mpiserial ;; Executes serial programs via MPI

copygb2={ENV[COPYGB2]}
grb2index={ENV[GRB2INDEX]}

# The rest of these are compiled by the HWRF sorc/ build system:
#NOW HMON
hafs_get_rtofs={EXEChwrf}/hafs_get_rtofs.x
hafs_rtofs_subregion={EXEChwrf}/hafs_rtofs_subregion.x
hafs_isubregion2avg={EXEChwrf}/hafs_isubregion2avg.x
hafs_rtofs_hat10_forecast={EXEChwrf}/hafs_rtofs_hat10_forecast.x
hafs_rtofs_hep20_forecast={EXEChwrf}/hafs_rtofs_hep20_forecast.x
hafs_rtofs_hcp70_forecast={EXEChwrf}/hafs_rtofs_hcp70_forecast.x
hafs_rtofs_hin40_forecast={EXEChwrf}/hafs_rtofs_hin40_forecast.x
hafs_rtofs_hsn50_forecast={EXEChwrf}/hafs_rtofs_hsn50_forecast.x
hafs_rtofs_hsp60_forecast={EXEChwrf}/hafs_rtofs_hsp60_forecast.x
hafs_rtofs_hwp30_forecast={EXEChwrf}/hafs_rtofs_hwp30_forecast.x
hafs_getkpds={EXEChwrf}/hafs_getkpds.x
hafs_getgds2={EXEChwrf}/hafs_getgds2.x
hafs_gfs2ofs2={EXEChwrf}/hafs_gfs2ofs2.x
hafs_timeinterp_forcing={EXEChwrf}/hafs_timeinterp_forcing.x
hafs_correct_forcing={EXEChwrf}/hafs_correct_forcing.x
hafs_archv2restart={EXEChwrf}/hafs_archv2restart.x
hafs_restart2restart={EXEChwrf}/hafs_restart2restart.x
hafs_fwind={EXEChwrf}/hafs_fwind.x
hafs_wind2hycom={EXEChwrf}/hafs_wind2hycom.x
hafs_correct_wind={EXEChwrf}/hafs_correct_wind.x
hafs_archv2data2d={EXEChwrf}/hafs_archv2data2d.x
hafs_archv2data3z={EXEChwrf}/hafs_archv2data3z.x
gfs2ofsinputs.py={USHhwrf}/hmon/gfs2ofsinputs.py

# -----------------------------------------------------------------------
# Preprocessing configuration.
# -----------------------------------------------------------------------

## Configures the hwrf_expt.gfs_init
[ungrib]

# -----------------------------------------------------------------------
# POST configuration.
# -----------------------------------------------------------------------
## Configures the hwrf.gribtask
[regribber]

# ----------------------------------------------------------------------
# HYCOM configuration.
# ----------------------------------------------------------------------

## hycom_init1 job configuration:
[hycominit1]
catalog={input_catalog}

RTOFS_HIST=/dev/null  ;; RTOFS .a and .b file locations of historical RTOFS
RTOFS_FCST=/dev/null  ;; RTOFS .a and .b file locations of real-time RTOFS
RTOFS_TAR=/dev/null   ;; RTOFS .a.tgz and .b file locations
RTOFS_TAR={rtofs}/rtofs.{aYMD}   ;; RTOFS .a.tgz and .b file locations
RTOFS_STAGE={WORKhwrf}/hycominit1/RTOFSDIR ;; RTOFS staging/linking area
#net yetRTOFS_STAGE={rtofs}/rtofs.{aYMD};; RTOFS staging/linking area

scrub=no              ;; Override global scrubbing option for hycom init

bools=hycombools      ;; Section with YES/NO variables for shell programs
strings=hycomstrings  ;; Section with string variables for shell programs

## hycom forecast program for the coupled forecast job
forecast_exe={EXEChwrf}/hmon_{RUNmodIDout}_forecast

## Output restart files; should contain RUNmodIDout and ab vars
restart_outR={com}/{out_prefix}.{RUNmodIDout}.spin_restart.{ab}
## Output restart R files; should contain RUNmodIDout and ab vars
restart_out={com}/{out_prefix}.{RUNmodIDout}.restart.{ab}
## Output spin files; should contain RUNmodIDout and ab vars
spin_archv={com}/{out_prefix}.spin_archv.{ab}

## Enable river adjustment in HYCOM initialization?
adjust_river=0

## Enable temperature adjustment in HYCOM initialization?
adjust_temp=0

## Interval in hours between forcing in the 126hr forecast mode
forecast_forcing_interval=3

## Adjust wind near hurricane in HYCOM initialization?
parameterized_winds=0

## Number of hycom processors
hycom_procs=150

atmos1_dataset=gdas1      ;; Dataset for global atmospheric surface data before time 0
atmos1_flux=gdas1_sfluxgrb ;; Item for atmospheric flux data before time 0
atmos1_grid=gdas1_gribA   ;; Item for atmospheric air data before time 0
atmos2_dataset=gfs        ;; Dataset for global atmospheric surface data after time 0
atmos2_flux=gfs_sfluxgrb  ;; Item for atmospheric flux data after time 0
atmos2_grid=gfs_gribA     ;; Item for atmospheric air data after time 0
ocean_dataset=rtofs       ;; Dataset for global ocean archv data
ocean_fcst=rtofs_fcst     ;; Item for ocean data after analysis time
ocean_past=rtofs_past     ;; Item for ocean data before the analysis time
ocean_now=rtofs_now       ;; Item for ocean data at the analysis time
ocean_rst=rtofs_rst       ;; Item for ocean restart files
ocean_dataset_stage=rtofsstage       ;; Dataset for global ocean archv data (staged)
ocean_fcst_name=rtofs_fcst_name     ;; Item for ocean data after analysis time
ocean_past_name=rtofs_past_name     ;; Item for ocean data before the analysis time
ocean_now_name=rtofs_now_name       ;; Item for ocean data at the analysis time
ocean_rst_name=rtofs_rst_name       ;; Item for ocean restart files

## hycom_init2 job configuration:
[hycominit2]
catalog={input_catalog}

scrub=no              ;; Override global scrubbing option for hycom init

bools=hycombools      ;; Section with YES/NO variables for shell programs
strings=hycomstrings  ;; Section with string variables for shell programs

## Interval in hours between forcing in the 126hr forecast mode
forecast_forcing_interval=3

## Adjust wind near hurricane in HYCOM initialization?
parameterized_winds=0

atmos1_dataset=gdas1      ;; Dataset for global atmospheric surface data before time 0
atmos1_flux=gdas1_sfluxgrb ;; Item for atmospheric flux data before time 0
atmos1_grid=gdas1_gribA   ;; Item for atmospheric air data before time 0
atmos2_dataset=gfs        ;; Dataset for global atmospheric surface data after time 0
atmos2_flux=gfs_sfluxgrb  ;; Item for atmospheric flux data after time 0
atmos2_grid=gfs_gribA     ;; Item for atmospheric air data after time 0

## Configuration for the ocean_post job
[hycompost]
bools=hycombools     ;; Section with YES/NO variables for shell programs
strings=hycomstrings ;; Section with string variables for shell programs

## This section contains YES/NO variables and values which will be set
## as environment variables in the shell programs.
#
# The hycombools section is filled with ENV_VAR=value entries.  Each
# ENV_VAR will be set to the boolean version of the value.  Values are
# converted to Python booleans and then to the strings YES or NO.  All
# environment variables must be valid shell and Python variable names.
[hycombools]
RUN_OCEAN={run_ocean}
RUN_WAVE={run_wave}

## This section contains variables and string values which will be set
## as environment variables in the shell programs.
#
# The hycomstrings section is filled with ENV_VAR=value entries.  The
# ENV_VAR will be set to the value, unmodified.  All environment
# variables must be valid shell and Python variable names.  The
# strings must be single line strings (no end-of-line characters) that
# are expressable in both shell and Python.  
#
# @note The special RTOFSDIR variable is set independently based on
# the hwrf.hycom.HYCOMInit.find_rtofs_data() function.
[hycomstrings]
NPROCS_o=150
out_prefix={config/out_prefix}
out_prefix_nodate={config/out_prefix_nodate}
FORECAST_DIR={dir/WORKhwrf}/runwrf
OCEAN_MODEL={ocean_model}
WAVE_MODEL={wave_model}
YMDH={config/YMDH}
stormlabel={config/stormlabel}
STORM={vit[stormname]}
STID={vit[stormid3]}
basin2={vit[pubbasin2]}
USHhwrf={dir/USHhwrf}
FIXhwrf={dir/FIXhwrf}
PARMhwrf={dir/PARMhwrf}
EXEChwrf={dir/EXEChwrf}
COMhwrf={config/com}
WORKhwrf={dir/WORKhwrf}
CASE_ROOT={config/case_root}

