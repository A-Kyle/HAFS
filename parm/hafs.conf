## This is a UNIX conf file that contains all information relating to
# the HAFS configuration.  UNIX conf is used because of how easy it is
# to parse (even GrADS can do it).  The syntax:
#
#      [section]
#      var = value
#
# For generation of namelists for Fortran programs, we use this syntax:
#
#     [section]
#     namelist.nlvar = value
#
# to set the value of namelist &namelist's nlvar variable.  Also, the
# special variable "namelist" lists additional conf sections to
# recurse into to get more namelist variables after the current conf
# section is parsed.  Any variable will only be set once: the first
# time it is seen.

## Sets basic configuration options used by all components.
#
# This section sets basic configuration options used by all components.  
# Several special variables in this section are set by the ProdConfig 
# object itself, which will overwrite them if they're set in this
# file:
# * YMDHM = analysis time (201304261830 = April 26, 2013, 18:30 UTC)
# * YMDH = analysis time excluding minute (2013042618)
# * YMD = analysis time, excluding hour and minute
# * year, YYYY = analysis time's year (ie.: 2013)
# * YY = last two digits of year
# * century, CC = first two digits of year
# * month, MM = analysis time's month (ie.: 04)
# * day, DD = analysis time's day (ie.: 26)
# * hour, cyc, HH = analysis time's hour (ie.: 18)
# * minute, min = analysis time's minute (ie.: 30)
#
# There may be additional variables depending on what subclass (if
# any) of the ProdConfig is used.  You must specify the mandatory EXPT
# value, which is the name of the experiment to run.
[config]
## The main configuration file.
CONFhafs={com}/{stormlabel}.conf

## The holdvars file.
HOLDVARS={com}/{stormlabel}.holdvars.txt

# RUNhafs is a component of some other file paths
RUNhafs={SUBEXPT}

# Prefix to prepend to most output files in the COM directory.
out_prefix={vit[stormnamelc]}{vit[stnum]:02d}{vit[basin1lc]}.{vit[YMDH]}
out_prefix_nodate={vit[stormnamelc]}{vit[stnum]:02d}{vit[basin1lc]}
old_out_prefix={oldvit[stormnamelc]}{oldvit[stnum]:02d}{oldvit[basin1lc]}.{oldvit[YMDH]}
old_out_prefix_nodate={oldvit[stormnamelc]}{oldvit[stnum]:02d}{oldvit[basin1lc]}

GFSVER=PROD2019       ;; GFS version (placeholder)
ENS=99                ;; The ensemble number (placeholder)

# Pull data from external sources to a staging area.  
# Specifies a section (default: [hafsdata]) to use: hafsdata, wcoss_fcst_nco
input_catalog=hafsdatatmp ;; (placeholder)

## Configure file and directory paths
[dir]
HOMEhafs={CDSAVE}/{EXPT}
WORKhafs={CDSCRUB}/{RUNhafs}/{vit[YMDH]}/{vit[stormid3]}
COMhafs={CDSCRUB}/{RUNhafs}/com/{vit[YMDH]}/{vit[stormid3]}
com={CDSCRUB}/{RUNhafs}/com/{vit[YMDH]}/{vit[stormid3]}
realstormcom={CDSCRUB}/{RUNhafs}/com/{YMDH}/{realstorm}
realstormwork={CDSCRUB}/{RUNhafs}/{YMDH}/{realstorm}
oldsid={oldvit[stormid3]}
oldcom={CDSCRUB}/{RUNhafs}/com/{oldvit[YMDH]}/{oldvit[stormid3]}
intercom={WORKhafs}/intercom                ;; dir for communicating data files between jobs
outatcf={CDNOSCRUB}/{SUBEXPT}               ;; Delivery location for ATCF files
outdiag={CDNOSCRUB}/diagtrak/{SUBEXPT}      ;; Delivery location for wrfdiag files
outstatus={CDNOSCRUB}/cycstatus/{SUBEXPT}   ;; Delivery location for status files
outatcfcorrected={CDNOSCRUB}/atcf/{SUBEXPT} ;; delivery location for corrected ATCF files
outships={CDNOSCRUB}/ships/{SUBEXPT}        ;; delivery location for SHIPS files
statusfile={WORKhafs}/{stormlabel}.{YMDH}   ;; cycle status file
## Domain center location file in COM.
domlocfile={com}/{vit[stnum]:02d}{vit[basin1lc]}.{vit[YMDH]}.domain.center
## File to check in a prior cycle's com, to see if the cycle exists.
HISTCHECK={oldcom}/{oldvit[stnum]:02d}{oldvit[basin1lc]}.{oldvit[YMDH]}.domain.center
## The name of the gsi status file in the com directory
gsistatus={stormlabel}.gsi_status
## Operational name of the gsi status file
gsistatus2=gsi_status.{vit[stormname]}{vit[stnum]:02d}{vit[basin1lc]}.{cycle}

PARMgsi={PARMhafs}/hafs-gsi/                ;; GSI input data for everything except CRTM
FIXcrtm={FIXhafs}/hafs-crtm-2.2.3/          ;; GSI CRTM input data

utilexec={HOMEhafs}/exec                    ;; utility exe location (placeholder)

## Executable program locations
# Currently not used in the workflow script system
[exe]
## grib_utils util programs: need load the grib_util module
# cnvgrib, copygb, copygb2, degrib2, grb2index, grbindex, grib2grib, wgrib, wgrib2

# tar/htar/hsi: These three are not used in EMC-maintained production
# jobs since NCO maintains ksh-based archiving jobs.  When EMC runs,
# we get these from the $PATH:
tar=tar    ;; GNU Tar
htar=htar  ;; HTAR tape archiving program
hsi=hsi    ;; hsi tape manipulation program

mpiserial={EXEChafs}/mpiserial ;; Executes serial programs via MPI (placeholder)

# The rest of these are compiled by the HAFS sorc/ build system:
forecast={EXEChafs}/hafs_forecast.x

post={EXEChafs}/hafs_post.x

chgres={EXEChafs}/hafs_chgres.x

orog={EXEChafs}/hafs_orog.x

make_hgrid={EXEChafs}/hafs_make_hgrid.x
make_solo_mosaic={EXEChafs}/hafs_make_solo_mosaic.x
fregrid={EXEChafs}/hafs_fregrid.x
filter_topo={EXEChafs}/hafs_filter_topo.x
shave={EXEChafs}/hafs_shave.x

gettrk={EXEChafs}/hafs_gettrk.x
tave={EXEChafs}/hafs_tave.x
vint={EXEChafs}/hafs_vint.x
supvit={EXEChafs}/hafs_supvit.x

gsi={EXEChafs}/hafs_gsi.x
enkf={EXEChafs}/hafs_enkf.x

## Configure the prelaunch configuration overrides, run in
## hafs_expt, and implemented in hafs.prelaunch
[prelaunch]
# Per-forecast-center configurations
rsmc_overrides=no      ;; read parm/hafs_JTWC.conf and parm/hafs_NHC.conf
rsmc_conf={PARMhafs}/hafs_{RSMC}.conf  ;; File to read for rsmc_overrides
# Per-basin configurations: read no_basin_conf if basin_conf is missing
basin_overrides=yes    ;; read parm/hafs_(basin).conf
# File to read for recognized basins when basin_overrides is enabled
basin_conf={PARMhafs}/hafs_{vit.pubbasin2}.conf
# File to read for unrecognized basins when basin_overrides is enabled
no_basin_conf={PARMhafs}/hafs_other_basins.conf

[launch]

[sanity]

[grid_driver]

[input]

[chgres_ic]

[chgres_bc]

[vortexinit]

[bufrprep]

[fgat]

[gsi]

[enkf]

[merge]

[forecast]

[post]

[product]

[tracker]

[archive]
mkdir=yes     ;; make the archive directory? yes or no

## Variables to set as string values when parsing the hafs_workflow.xml.in.
# This section is only used by the rocoto-based workflow
[rocotostr]
CDSAVE={dir/CDSAVE}                 ;; save area for Rocoto to use
CDNOSCRUB={dir/CDNOSCRUB}           ;; non-scrubbed area for Rocoto to use
CDSCRUB={dir/CDSCRUB}               ;; scrubbed area for Rocoto to use
PARMhafs={dir/PARMhafs}             ;; parm/ directory location
USHhafs={dir/USHhafs}               ;; ush/ directory location
EXhafs={dir/EXhafs}                 ;; scripts/ directory location
JOBhafs={dir/JOBhafs}               ;; scripts/ directory location
EXPT={config/EXPT}                  ;; experiment name
SUBEXPT={config/SUBEXPT}            ;; sub-experiment name
CPU_ACCOUNT={cpu_account}           ;; CPU account name

# Variables to set as boolean values when parsing the hafs_workflow.xml.in. 
# They'll be changed to YES or NO.  This section is only used by the rocoto-based workflow.
[rocotobool]
RUN_GSI={run_gsi}                   ;; Do we run GSI?
RUN_OCEAN={run_ocean}               ;; Do we run with ocean coupling?
RUN_WAVE={run_wave}                 ;; Do we run with wave coupling?
RUN_VORTEXINIT={run_vortexinit}     ;; Do we enable vortex initialization?
SCRUB_COM={scrub_com}               ;; Should Rocoto scrub the COM directory?
SCRUB_WORK={scrub_work}             ;; Should Rocoto scrub the WORK directory?

